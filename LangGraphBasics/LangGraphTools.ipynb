{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üõ†Ô∏è Mastering Tools in LangGraph: From Functions to MCP\n",
    "\n",
    "In this notebook, we‚Äôll build an AI agent that doesn't just talk‚Äîit **acts**. We will cover:\n",
    "1. **Custom Python Tools** using the `@tool` decorator.\n",
    "2. **The Prebuilt `ToolNode`** for automated execution.\n",
    "3. **Model Context Protocol (MCP)** for standardized external integration.\n",
    "4. **The Feedback Loop**: How agents learn from tool results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary dependencies\n",
    "!pip install -U langgraph langchain-openai langchain-mcp-adapters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Defining Real-World Python Tools\n",
    "Let's create a tool for a **Travel Agent**. This agent needs to fetch weather and calculate flight carbon offsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def get_weather(city: str):\n",
    "    \"\"\"Consult this tool to get the current weather for a specific city.\"\"\"\n",
    "    if \"london\" in city.lower():\n",
    "        return \"It's currently 15¬∞C and rainy.\"\n",
    "    return \"It's a beautiful 25¬∞C and sunny.\"\n",
    "\n",
    "@tool\n",
    "def carbon_offset_calculator(miles: int):\n",
    "    \"\"\"Calculates the carbon offset cost in USD for a flight based on mileage.\"\"\"\n",
    "    # Simple logic: $0.05 per mile\n",
    "    return f\"The carbon offset cost for {miles} miles is ${miles * 0.05:.2f}.\"\n",
    "\n",
    "tools = [get_weather, carbon_offset_calculator]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting up the Prebuilt ToolNode\n",
    "LangGraph's `ToolNode` acts as the \"hands\" of our agent. It listens for `tool_calls` in the LLM's message and runs them automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Integrating MCP (Model Context Protocol)\n",
    "MCP allows you to connect to a universe of servers (SQLite, Slack, GitHub) without writing custom wrappers for every API.\n",
    "\n",
    "*Note: In a real scenario, you'd have an MCP server running. Here is how you'd connect to it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "\n",
    "try:\n",
    "    # Example: Connecting to a local MCP server managing a database\n",
    "    # mcp_tools = load_mcp_tools(\"http://localhost:8000/mcp\")\n",
    "    # all_tools = tools + mcp_tools\n",
    "    all_tools = tools # Staying with local tools for this demo\n",
    "    print(\"MCP tools loaded successfully!\")\n",
    "except Exception as e:\n",
    "    all_tools = tools\n",
    "    print(f\"MCP not found, proceeding with basic tools. Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building the Graph\n",
    "We use `MessagesState` to keep track of the conversation history, including the tool outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Bind the tools to the model so it knows they exist\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", api_key=\"YOUR_OPENAI_API_KEY\")\n",
    "llm_with_tools = llm.bind_tools(all_tools)\n",
    "\n",
    "def chatbot(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Add nodes\n",
    "builder.add_node(\"agent\", chatbot)\n",
    "builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Define edges\n",
    "builder.add_edge(START, \"agent\")\n",
    "builder.add_conditional_edges(\"agent\", tools_condition)\n",
    "builder.add_edge(\"tools\", \"agent\") # Circle back to agent to summarize results\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Running the Agent\n",
    "Watch how the agent calls multiple tools to answer a complex request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"messages\": [(\"user\", \"I'm flying 2000 miles to London. What's the weather there and how much will my carbon offset be?\")]}\n",
    "\n",
    "for output in graph.stream(inputs, stream_mode=\"updates\"):\n",
    "    for node, values in output.items():\n",
    "        print(f\"--- Node: {node} ---\")\n",
    "        last_msg = values[\"messages\"][-1]\n",
    "        if hasattr(last_msg, \"tool_calls\") and last_msg.tool_calls:\n",
    "            print(f\"Action: Calling tools { [t['name'] for t in last_msg.tool_calls] }\")\n",
    "        else:\n",
    "            print(f\"Content: {last_msg.content[:100]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}