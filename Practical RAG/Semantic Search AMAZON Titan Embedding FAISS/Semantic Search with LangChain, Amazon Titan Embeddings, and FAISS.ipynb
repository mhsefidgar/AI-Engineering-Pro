{
  "cells": [
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "# üöÄ Semantic Intelligence: Building a PDF Vector Brain\n",
     "### **Powered by Mohammad Sefidgar**\n",
     "\n",
     "Welcome to a masterclass in modern AI retrieval. This notebook transforms static PDF documents into a high-performance, semantically aware vector database. We utilize the power of **Amazon Bedrock**, **LangChain**, and **FAISS** to create a system that doesn't just look for keywords‚Äîit understands meaning.\n",
     "\n",
     "![Diagram](data/build_pdf_vector_db.jpg)"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## üõ†Ô∏è The Power Stack\n",
     "To run this engine, you'll need the following tools in your environment:\n",
     "\n",
     "* **Boto3**: The AWS SDK for Python to communicate with Amazon Bedrock.\n",
     "* **LangChain**: The orchestrator for our LLM and vector workflows.\n",
     "* **FAISS**: Facebook AI Similarity Search, our high-speed vector engine.\n",
     "* **PyPDF**: To unlock and read PDF data.\n",
     "* **SemanticChunker**: Part of LangChain Experimental for meaning-based splitting."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "#!pip install -qU boto3 langchain langchain-community langchain-aws langchain-experimental pypdf faiss-cpu"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "import boto3\n",
     "import os\n",
     "import numpy as np\n",
     "from langchain_aws import BedrockEmbeddings\n",
     "from langchain_community.vectorstores import FAISS\n",
     "from langchain_community.document_loaders import PyPDFLoader\n",
     "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
     "from langchain_experimental.text_splitter import SemanticChunker\n",
     "\n",
     "# Initialize the Bedrock Client - Mohammad Sefidgar Configuration\n",
     "bedrock_client = boto3.client(\"bedrock-runtime\", region_name='us-east-1') \n",
     "\n",
     "# Powering our intelligence with Amazon Bedrock Embeddings\n",
     "# We use Cohere Multilingual for robust cross-language semantic understanding.\n",
     "embeddings_model = BedrockEmbeddings(\n",
     "    model_id=\"cohere.embed-multilingual-v3\", \n",
     "    client=bedrock_client\n",
     ")\n",
     "\n",
     "print(\"‚úÖ Connection to Amazon Bedrock established.\")"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## üìÇ 2. Interactive PDF Upload\n",
     "Instead of using hardcoded paths, this section allows you to process any custom document on the fly. Simply provide the path to your PDF file."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# Interactive Input powered by Mohammad Sefidgar's workflow\n",
     "custom_pdf_path = input(\"Enter the path to your PDF file (e.g., my_document.pdf): \")\n",
     "\n",
     "if not os.path.exists(custom_pdf_path):\n",
     "    print(\"‚ùå File not found. Please ensure the path is correct!\")\n",
     "else:\n",
     "    print(f\"üìñ Successfully located: {custom_pdf_path}\")"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## ‚úÇÔ∏è 3. Smart Splitting: Recursive vs. Semantic\n",
     "How we cut the text determines how well the AI \"remembers\" it. \n",
     "\n",
     "1. **Recursive Character Splitting**: Slices text based on natural pauses (newlines, spaces) with context overlap.\n",
     "2. **Semantic Chunking**: Analyzes the text using the language model to divide it into sections that have a coherent meaning."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "def process_document(file_path, method=\"semantic\"):\n",
     "    loader = PyPDFLoader(file_path)\n",
     "    \n",
     "    if method == \"recursive\":\n",
     "        # Traditional high-speed splitting\n",
     "        splitter = RecursiveCharacterTextSplitter(\n",
     "            chunk_size=1000, \n",
     "            chunk_overlap=100\n",
     "        )\n",
     "        docs = loader.load_and_split(splitter)\n",
     "    else:\n",
     "        # Advanced meaning-based splitting\n",
     "        splitter = SemanticChunker(embeddings_model, breakpoint_threshold_amount=80)\n",
     "        raw_docs = loader.load()\n",
     "        docs = splitter.split_documents(raw_docs)\n",
     "        \n",
     "    # Clean up empty fragments\n",
     "    clean_docs = [doc for doc in docs if len(doc.page_content) > 0]\n",
     "    return clean_docs\n",
     "\n",
     "# Applying Mohammad Sefidgar's semantic logic\n",
     "processed_docs = process_document(custom_pdf_path, method=\"semantic\")\n",
     "print(f\"‚ú® Created {len(processed_docs)} semantically coherent chunks.\")"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## üß† 4. Building the Vector Brain (FAISS)\n",
     "We convert the text chunks into mathematical vectors and store them in **FAISS**. This allows for quick similarity searches and retrieval of related documents.\n",
     "\n",
     ""
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "vector_db = FAISS.from_documents(processed_docs, embeddings_model)\n",
     "print(f\"üß† Vector Database ready with {vector_db.index.ntotal} indexed nodes.\")"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## üîç 5. Interrogating Your Data\n",
     "We can perform a simple similarity search or a search that returns confidence scores.\n",
     "\n",
     ""
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "query = \"What is the main topic of this document?\"\n",
     "\n",
     "# Similarity search with score\n",
     "results = vector_db.similarity_search_with_score(query, k=2)\n",
     "\n",
     "for res, score in results:\n",
     "    print(f\"* [SIM_SCORE={score:3f}] {res.page_content[:200]}... [{res.metadata}]\")"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## üíæ 6. Local Persistence & Management\n",
     "You can save the vector store locally to avoid re-processing the entire PDF in future sessions."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "db_folder = \"custom_pdf_index\"\n",
     "vector_db.save_local(db_folder)\n",
     "print(f\"üíæ Vector index successfully saved to {db_folder}\")\n",
     "\n",
     "# Loading the database back\n",
     "new_db = FAISS.load_local(db_folder, embeddings_model, allow_dangerous_deserialization=True)\n",
     "\n",
     "# Checking total count\n",
     "print(f\"Loaded database contains {new_db.index.ntotal} records.\")"
    ]
   }
  ],
  "metadata": {
   "kernelspec": {
    "display_name": "python3",
    "language": "python",
    "name": "python3"
   },
   "language_info": {
    "codemirror_mode": {
     "name": "ipython",
     "version": 3
    },
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": "3.10.0"
   }
  },
  "nbformat": 4,
  "nbformat_minor": 2

 }
