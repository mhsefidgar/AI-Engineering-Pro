{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xc9j2MkKwOtq"
      },
      "source": [
        "# üöÄ Semantic Intelligence: Building a PDF Vector Brain\n",
        "### **Powered by Mohammad Sefidgar**\n",
        "\n",
        "Welcome to a masterclass in modern AI retrieval. This notebook transforms static PDF documents into a high-performance, semantically aware vector database. We utilize the power of **Hugging Face**, **LangChain**, and **FAISS** to create a system that doesn't just look for keywords‚Äîit understands meaning.\n",
        "\n",
        "![Diagram](https://github.com/mhsefidgar/AI-Engineering-Pro/blob/main/Practical%20RAG/Semantic%20Search%20AMAZON%20Titan%20Embedding%20FAISS/data/build_pdf_vector_db.jpg?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fnK3O_0wOtr"
      },
      "source": [
        "## üõ†Ô∏è The Power Stack\n",
        "To run this engine, you'll need the following tools in your environment:\n",
        "\n",
        "* **Hugging Face**: Local embeddings for semantic understanding without API keys.\n",
        "* **LangChain**: The orchestrator for our LLM and vector workflows.\n",
        "* **FAISS**: Facebook AI Similarity Search, our high-speed vector engine.\n",
        "* **PyPDF**: To unlock and read PDF data.\n",
        "* **SemanticChunker**: Part of LangChain Experimental for meaning-based splitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9W4-l7CcwOts"
      },
      "outputs": [],
      "source": [
        "# Install local processing requirements\n",
        "!pip install -qU langchain-huggingface sentence-transformers\n",
        "!pip install -qU langchain-community pypdf faiss-cpu\n",
        "!pip install -qU langchain-experimental"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBHxe7zUwOtt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "# Powering our intelligence with Local Hugging Face Embeddings\n",
        "# 'all-MiniLM-L6-v2' is fast, accurate, and runs locally without any credentials.\n",
        "embeddings_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "print(\"‚úÖ Local Hugging Face Embeddings initialized.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTNXWC9OwOtt"
      },
      "source": [
        "## üìÇ 2. Interactive PDF Upload\n",
        "Instead of using hardcoded paths, this section allows you to process any custom document on the fly. Simply provide the path to your PDF file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwVscuS_wOtt"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "if not uploaded:\n",
        "    print(\"‚ùå No file uploaded.\")\n",
        "else:\n",
        "    custom_pdf_path = list(uploaded.keys())[0]\n",
        "    if os.path.exists(custom_pdf_path):\n",
        "        print(f\"üìñ Successfully uploaded and located: {custom_pdf_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7M6_D0RwOtt"
      },
      "source": [
        "## üß† 3. Advanced Document Processing\n",
        "We can process the document using two methods: Traditional Recursive splitting or Advanced Semantic splitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qR6u_D2SwOtt"
      },
      "outputs": [],
      "source": [
        "def process_document(file_path, method=\"semantic\"):\n",
        "    loader = PyPDFLoader(file_path)\n",
        "    \n",
        "    if method == \"recursive\":\n",
        "        # Traditional high-speed splitting\n",
        "        splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=1000, \n",
        "            chunk_overlap=100\n",
        "        )\n",
        "        docs = loader.load_and_split(splitter)\n",
        "    else:\n",
        "        # Advanced meaning-based splitting using local embeddings\n",
        "        splitter = SemanticChunker(embeddings_model, breakpoint_threshold_amount=80)\n",
        "        raw_docs = loader.load()\n",
        "        docs = splitter.split_documents(raw_docs)\n",
        "        \n",
        "    # Clean up empty fragments\n",
        "    clean_docs = [doc for doc in docs if len(doc.page_content) > 0]\n",
        "    return clean_docs\n",
        "\n",
        "# Applying Mohammad Sefidgar's semantic logic\n",
        "processed_docs = process_document(custom_pdf_path, method=\"semantic\")\n",
        "print(f\"‚ú® Created {len(processed_docs)} semantically coherent chunks.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU6u_D4TwOtt"
      },
      "source": [
        "## üèóÔ∏è 4. Vector Database Construction\n",
        "Injecting our semantically processed documents into FAISS for lightning-fast retrieval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pA6u_D6UwOtt"
      },
      "outputs": [],
      "source": [
        "vector_db = FAISS.from_documents(processed_docs, embeddings_model)\n",
        "print(f\"üèóÔ∏è Vector database created with {vector_db.index.ntotal} vectors.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rS6u_D8VwOtt"
      },
      "source": [
        "## üîç 5. Precision Semantic Retrieval\n",
        "Testing the brain's ability to find relevant information based on meaning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tF6u_D-WwOtt"
      },
      "outputs": [],
      "source": [
        "query = \"What are the key findings or main topics in this document?\"\n",
        "results = vector_db.similarity_search(query, k=3)\n",
        "\n",
        "print(f\"\\nüîç Query: {query}\\n\")\n",
        "for i, res in enumerate(results):\n",
        "    print(f\"[Result {i+1}]: {res.page_content[:200]}... [{res.metadata}]\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUEZz_wQwOtv"
      },
      "source": [
        "## üíæ 6. Local Persistence & Management\n",
        "Save the vector store locally to avoid re-processing in future sessions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6uw_Dc8wOtv"
      },
      "outputs": [],
      "source": [
        "db_folder = \"custom_pdf_index\"\n",
        "vector_db.save_local(db_folder)\n",
        "print(f\"üíæ Vector index successfully saved to {db_folder}\")\n",
        "\n",
        "# Loading the database back\n",
        "new_db = FAISS.load_local(db_folder, embeddings_model, allow_dangerous_deserialization=True)\n",
        "\n",
        "print(f\"Loaded database contains {new_db.index.ntotal} records.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
